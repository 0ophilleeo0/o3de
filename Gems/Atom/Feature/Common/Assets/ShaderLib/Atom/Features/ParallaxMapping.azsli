/*
* All or portions of this file Copyright (c) Amazon.com, Inc. or its affiliates or
* its licensors.
*
* For complete copyright and license terms please see the LICENSE at the root of this
* distribution (the "License"). All use of this software is governed by the License,
* or, if provided, by the license below or the license accompanying this file. Do not
* remove or modify any license notices. This file is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
*
*/

#pragma once

#include <Atom/RPI/TangentSpace.azsli>

option bool o_parallax_enablePixelDepthOffset;

option enum class ParallaxAlgorithm {Basic, Steep, POM, Relief, Contact} o_parallax_algorithm;
option enum class ParallaxQuality {Low, Medium, High, Ultra} o_parallax_quality;

option bool o_parallax_feature_enabled;
option bool o_parallax_highlightClipping;
option bool o_parallax_shadow;

//! The client shader must define this function.
//! This allows the client shader to implement special depth map sampling, for example procedurally generating or blending depth maps.
//! @param uv the UV coordinates to use for sampling
//! @param uv_ddx will be set to ddx_fine(uv)
//! @param uv_ddy will be set to ddy_fine(uv)
float GetDepth(float2 uv, float2 uv_ddx, float2 uv_ddy);

//! Convenience function that can be used to implement GetDepth().
//! @param isHeightmap indicates whether to sample the map is a height map rather than a depth map.
float SampleDepthOrHeightMap(bool isHeightmap, Texture2D map, sampler mapSampler, float2 uv, float2 uv_ddx, float2 uv_ddy)
{
    return abs((isHeightmap * 1.0) - map.SampleGrad(mapSampler, uv, uv_ddx, uv_ddy).r);
}

float GetClampedDepth(float minSampledDepth, float2 uv, float2 uv_ddx, float2 uv_ddy)
{
    float sampledDepthValue = GetDepth(uv, uv_ddx, uv_ddy);
    sampledDepthValue = max(sampledDepthValue, minSampledDepth);
    return sampledDepthValue;
}

struct ParallaxOffset
{
    float3 m_offsetTS;  //!< represents the intersection point relative to the geometry surface, in tangent space.
    bool m_isClipped;   //!< Indicates whether the result is being clipped by the geometry surface, mainly for debug rendering. Only set when o_parallax_highlightClipping is true.
};

// dirToCameraTS should be in tangent space and normalized
// From Reat-Time Rendering 3rd edition, p.192
ParallaxOffset BasicParallaxMapping(float depthFactor, float2 uv, float3 dirToCameraTS)
{
    // the amount to shift
    float2 delta = dirToCameraTS.xy * GetDepth(uv, ddx_fine(uv), ddy_fine(uv)) * depthFactor;
    
    ParallaxOffset result;

    result.m_offsetTS = float3(0,0,0);
    result.m_offsetTS.xy -= delta;
    result.m_isClipped = false;
    return result;
}

// Performs ray intersection against a surface with a heightmap.
// Adapted from CryEngine shader shadelib.cfi and POM function in https://github.com/a-riccardi/shader-toy
// check https://github.com/UPBGE/blender/issues/1009 for more details.
// @param depthFactor - scales the heightmap in tangent space units (which normally ends up being world units).
// @param depthOffset - offsets the heighmap up or down in tangent space units (which normally ends up being world units).
// @param uv - the UV coordinates on the surface, where the search will begin, used to sample the heightmap.
// @param dirToCameraTS - normalized direction to the camera, in tangent space.
// @param dirToLightTS - normalized direction to a light source, in tangent space, for self-shadowing (if enabled via o_parallax_shadow).
// @param numSteps - the number of steps to take when marching along the ray searching for intersection.
// @param parallaxShadowAttenuation - returns a factor for attenuating a light source, for self-shadowing (if enabled via o_parallax_shadow).
ParallaxOffset AdvancedParallaxMapping(float depthFactor, float depthOffset, float2 uv, float3 dirToCameraTS, float3 dirToLightTS, int numSteps, inout float parallaxShadowAttenuation)
{
    ParallaxOffset result;
    result.m_isClipped = false;

    float dirToCameraZInverse = 1.0 / dirToCameraTS.z;
    float step =  1.0 / numSteps;
    float currentStep = 0.0;

    // the amount to shift per step, shift in the inverse direction of dirToCameraTS
    float3 delta = -dirToCameraTS.xyz * depthFactor * dirToCameraZInverse * step;

    float2 ddx_uv = ddx_fine(uv);
    float2 ddy_uv = ddy_fine(uv);
    
    // This is the relative position at which we begin searching for intersection.
    // It is adjusted according to the depthOffset, raising or lowering the whole surface by depthOffset units.
    float3 parallaxOffset = dirToCameraTS.xyz * dirToCameraZInverse * depthOffset;
    
    // Note that depthOffset can raise the heightmap toward (and potentially above) the surface of the mesh.
    // We will clamp the heightmap samples to prevent displacements that lie above the surface, which would cause various 
    // problems especially when PDO is enabled, like parallax surfaces clipping through foreground geometry, and parallax 
    // surfaces disappearing at low angles.
    float minSampledDepth = depthOffset / depthFactor;
    minSampledDepth = clamp(minSampledDepth, 0, 1);

    // Get an initial heightmap sample to start the intersection search, starting at our initial parallaxOffset position.
    float currentSample = GetClampedDepth(minSampledDepth, uv + parallaxOffset.xy, ddx_uv, ddy_uv);
    float prevSample;
    
    // Note that when depthOffset > 0, we could actually narrow the search so that instead of going through the entire [0,1] range
    // of the heightmap, we could go through the range [minSampledDepth,1]. This would give more accurate results and fewer artifacts
    // in case where depthOffset is significant. But for the sake of simplicity we currently search the whole range in all cases.

    // Do a basic search for the intersect step
    while(currentSample > currentStep)
    {
        currentStep += step;
        parallaxOffset += delta;
                
        prevSample = currentSample;
        currentSample = GetClampedDepth(minSampledDepth, uv + parallaxOffset.xy, ddx_uv, ddy_uv);
    }

    // Depending on the algorithm, we refine the result of the above search
    switch(o_parallax_algorithm)
    {
        case ParallaxAlgorithm::Steep:
            break; // This algorithm just relies on the course intersection test loop above
        case ParallaxAlgorithm::POM:
        {
            if(currentStep > 0.0)
            {
                // linear interpolation between the previous offset and the current offset
                float prevStep = currentStep - step;
                float currentDiff = currentStep - currentSample;
                float prevDiff = prevSample - prevStep;
                float ratio = prevDiff/ (prevDiff + currentDiff);

                parallaxOffset = lerp(parallaxOffset - delta, parallaxOffset, ratio);
            }
            break;
        }
        case ParallaxAlgorithm::Relief:
        {
            if(currentStep > 0.0)
            {
                // Refining the parallax-offsetted uv, by binary searching around the naive intersection point
                float depthSign = 1;
                float3 reliefDelta = delta;
                float reliefStep = step;

                for(int i = 0; i < numSteps; i++)
                {
                    reliefDelta *= 0.5;
                    reliefStep *= 0.5;
                    depthSign = sign(currentSample - currentStep);

                    parallaxOffset += reliefDelta * depthSign;
                    currentStep += reliefStep * depthSign;

                    currentSample = GetClampedDepth(minSampledDepth, uv + parallaxOffset.xy, ddx_uv, ddy_uv);
                }
            }
            break;
        }
        case ParallaxAlgorithm::Contact:
        {
            if(currentStep > 0.0)
            {
                // Contact refinement propose by Andrea Riccardi 
                // https://www.artstation.com/andreariccardi/blog/3VPo/a-new-approach-for-parallax-mapping-presenting-the-contact-refinement-parallax-mapping-technique

                // Based on the rough approximation, rolling back to the previous step along the ray.
                parallaxOffset -= delta;
                currentStep -= step;
                currentSample = prevSample;

                // Adjust precision
                float3 adjustedDelta = delta * step;
                float adjustedStep = step * step;

                // Uses another loop with the same step numbers, this times only covers the distance between previous point and the rough intersection point.
                while(currentSample > currentStep)
                {
                    currentStep += adjustedStep;
                    parallaxOffset += adjustedDelta;
                    prevSample = currentSample;

                    currentSample = GetClampedDepth(minSampledDepth, uv + parallaxOffset.xy, ddx_uv, ddy_uv);
                }
            }
            break;
        }
        default:
            break;
    }
    
    // Even though we do a bunch of clamping above when calling GetClampedDepth(), there are still cases where the parallax offset
    // can be noticeably above the surface and still needs to be clamped here. The main case is when depthFactor==0 and depthOffset>1.
    if(parallaxOffset.z > 0.0)
    {
        result.m_isClipped = o_parallax_highlightClipping;
        parallaxOffset = float3(0,0,0);
    }
    // Extra check to report whether the heightmap is clipped. Inaccuracies in the intersection search make it difficult to rely on 
    // parallaxOffset.z to determine whether clipping has occurred. The most accurate way to report clipping is to sample the 
    // heightmap one last time at the final adjusted UV. Since that's expensive, we only do it when the o_parallax_highlightClipping
    // option is set.
    else if (o_parallax_highlightClipping)
    {
        float sampledDepthValue = GetDepth(uv + parallaxOffset.xy, ddx_uv, ddy_uv);
        result.m_isClipped = sampledDepthValue < minSampledDepth;
    }

    if(o_parallax_shadow && any(dirToLightTS))
    {
        float2 shadowUV = uv + parallaxOffset.xy;
        float shadowNumSteps = round(numSteps * currentStep);
        float shadowStep = 1.0 / shadowNumSteps;
        float dirToLightZInverse = 1.0 / dirToLightTS.z;
        float2 shadowDelta = dirToLightTS.xy * depthFactor * dirToLightZInverse * shadowStep;

        bool rayUnderSurface = false;
        float partialShadowFactor = 0;

        // Raytrace from found parallax-offsetted point to the light. 
        // parallaxShadowAttenuation represents how much the current point is shadowed.
        for(int i = 0 ; i < shadowNumSteps; i++)
        {
            // light ray is under surface
            if(currentSample < currentStep)
            {
                rayUnderSurface = true;
                partialShadowFactor = max(partialShadowFactor, (currentStep - currentSample) * (1 - (i + 1) * shadowStep));
            }

            shadowUV += shadowDelta;
            currentSample = GetClampedDepth(minSampledDepth, shadowUV, ddx_uv, ddy_uv);
            currentStep -= step;
        }

        if(rayUnderSurface)
        {
            parallaxShadowAttenuation = 1 - partialShadowFactor;
        }
        else
        {
            parallaxShadowAttenuation = 1;
        }
    }
    
    result.m_offsetTS = parallaxOffset;
    return result;
}

// return offset in tangent space
ParallaxOffset CalculateParallaxOffset(float depthFactor, float depthOffset, float2 uv, float3 dirToCameraTS, float3 dirToLightTS, inout float parallaxShadowAttenuation)
{
    if(o_parallax_algorithm == ParallaxAlgorithm::Basic)
    {
        return BasicParallaxMapping(depthFactor, uv, dirToCameraTS);
    }
    else
    {
        ParallaxOffset parallaxOffset;
        switch(o_parallax_quality)
        {
            case ParallaxQuality::Low:
                parallaxOffset = AdvancedParallaxMapping(depthFactor, depthOffset, uv, dirToCameraTS, dirToLightTS, 16, parallaxShadowAttenuation);
                break;
            case ParallaxQuality::Medium:
                parallaxOffset = AdvancedParallaxMapping(depthFactor, depthOffset, uv, dirToCameraTS, dirToLightTS, 32, parallaxShadowAttenuation);
                break;
            case ParallaxQuality::High:
                parallaxOffset = AdvancedParallaxMapping(depthFactor, depthOffset, uv, dirToCameraTS, dirToLightTS, 64, parallaxShadowAttenuation);
                break;
            case ParallaxQuality::Ultra:
                parallaxOffset = AdvancedParallaxMapping(depthFactor, depthOffset, uv, dirToCameraTS, dirToLightTS, 128, parallaxShadowAttenuation);
                break;
        }
        return parallaxOffset;
    }
}

// Performs ray intersection against a surface with a heightmap, to determine an offset amount required for a parallax effect.
// @param depthFactor - scales the heightmap in tangent space units (which normally ends up being world units).
// @param depthOffset - offsets the heighmap up or down in tangent space units (which normally ends up being world units).
// @param uv - the UV coordinates on the surface, where the search will begin, used to sample the heightmap.
// @param dirToCameraTS - normalized direction to the camera, in tangent space.
// @param dirToLightTS - normalized direction to a light source, in tangent space, for self-shadowing (if enabled via o_parallax_shadow).
ParallaxOffset GetParallaxOffset( float depthFactor, 
                          float depthOffset,
                          float2 uv,
                          float3 dirToCameraWS,
                          float3 tangentWS,
                          float3 bitangentWS,
                          float3 normalWS,
                          float3x3 uvMatrix)
{
    // Tangent space eye vector
    float3 dirToCameraTS = normalize(WorldSpaceToTangent(dirToCameraWS, normalWS, tangentWS, bitangentWS));

    // uv transform matrix in 3d, ignore translation
    float4x4 uv3DTransform;
    uv3DTransform[0] = float4(uvMatrix[0].xy, 0, 0);
    uv3DTransform[1] = float4(uvMatrix[1].xy, 0, 0);
    uv3DTransform[2] = float4(0, 0, 1, 0);
    uv3DTransform[3] = float4(0, 0, 0, 1);
    
    // Transform tangent space eye vector with UV matrix
    float4 dirToCameraTransformed = mul(uv3DTransform, float4(dirToCameraTS, 0.0));

    float dummy = 1;
    return CalculateParallaxOffset(depthFactor, depthOffset, uv, normalize(dirToCameraTransformed.xyz), float3(0,0,0), dummy);
}

struct PixelDepthOffset
{
    float m_depth;
    float3 m_worldPosition;
};

// Calculate Pixel Depth Offset and new world position
PixelDepthOffset CalcPixelDepthOffset(  float depthFactor, 
                                        float3 tangentOffset,
                                        float3 posWS,
                                        float3 tangentWS,
                                        float3 bitangentWS,
                                        float3 normalWS,
                                        float3x3 uvMatrixInverse,
                                        float4x4 objectToWorldMatrix,
                                        float4x4 viewProjectionMatrix)
{
    // uv transform inverse matrix in 3d, ignore translation
    float4x4 uv3DTransformInverse;
    uv3DTransformInverse[0] = float4(uvMatrixInverse[0].xy, 0, 0);
    uv3DTransformInverse[1] = float4(uvMatrixInverse[1].xy, 0, 0);
    uv3DTransformInverse[2] = float4(0, 0, 1, 0);
    uv3DTransformInverse[3] = float4(0, 0, 0, 1);
    
    tangentOffset = mul(uv3DTransformInverse, float4(tangentOffset, 0.0)).xyz;
    float3 worldOffset = TangentSpaceToWorld(tangentOffset, normalWS, tangentWS, bitangentWS);

    float scaleX = length(objectToWorldMatrix[0].xyz);
    float scaleY = length(objectToWorldMatrix[1].xyz);
    float scaleZ = length(objectToWorldMatrix[2].xyz);
    worldOffset *= float3(scaleX, scaleY, scaleZ);

    float3 worldOffsetPosition = posWS + worldOffset;
    float4 clipOffsetPosition = mul(viewProjectionMatrix, float4(worldOffsetPosition, 1.0));

    PixelDepthOffset pdo;
    pdo.m_depth = clipOffsetPosition.z / clipOffsetPosition.w;
    pdo.m_worldPosition = worldOffsetPosition;
    return pdo;
}
